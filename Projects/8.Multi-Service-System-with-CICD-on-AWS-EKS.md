
# üöÄ Intermediate Level ‚Äì Multi-Service System with CI/CD on AWS

This guide will walk you through setting up a multi-service "Blog Platform" on Amazon Web Services (AWS), incorporating a CI/CD pipeline with GitHub Actions.

## üéØ Project: "Blog Platform"

Your project will consist of the following components:

  * **Frontend**: A web application built with React or Vue.js.
  * **Backend API**: A Node.js or Laravel application handling business logic.
  * **Database**: PostgreSQL or MySQL for persistent data storage.
  * **Cache**: Redis for session management or caching.

## üì¶ Technologies You'll Master:

  * **Kubernetes (EKS)**: Orchestrating your containerized applications.
  * **GitHub Actions**: Automating your CI/CD pipeline.
  * **Helm**: Packaging and deploying Kubernetes applications.
  * **Amazon RDS**: Managed relational database service.
  * **Ingress Controller (AWS ALB Ingress)**: Managing external access and routing to your services.
  * **Secret Manager / ConfigMap**: Securely handling sensitive data and configurations.
  * **AWS CloudWatch**: Basic monitoring of your infrastructure.

-----

## ü™ú Overview Steps:

Here's a high-level overview of the deployment process:

1.  ‚òÅÔ∏è **Set up AWS Infrastructure**: Create your EKS cluster, RDS instance, and ElastiCache (Redis) instance.
2.  üê≥ **Containerize Your Services**: Create `Dockerfile`s for your Frontend and Backend.
3.  ‚öôÔ∏è **Create Helm Charts for Each Service**: Package your application configurations for Kubernetes.
4.  üîë **Manage Configurations and Secrets**: Use ConfigMaps for non-sensitive data and AWS Secrets Manager for sensitive data.
5.  üîÑ **Set up CI/CD with GitHub Actions**: Automate building, pushing, and deploying your services.
6.  üåê **Configure Ingress for Public Access**: Expose your Frontend and Backend APIs to the internet.
7.  üëÄ **Basic Monitoring with CloudWatch**: Observe your application's health.

-----

## Detailed Deployment Guide

Let's break down each step with examples. For this guide, we'll assume a **Node.js Backend** and a **React Frontend**.

### ‚òÅÔ∏è Step 1: Set Up AWS Infrastructure

Before deploying your applications, you need the foundational AWS services.

#### 1.1. **Create EKS Cluster**

You can use `eksctl` as demonstrated in the basic guide, or use the AWS Console.

**Using `eksctl` (Recommended):**

Create a `cluster-config.yaml` file:

```yaml
# cluster-config.yaml
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: blog-platform-cluster
  region: <your-aws-region> # e.g., us-east-1
  version: "1.28" # Choose a supported Kubernetes version

managedNodeGroups: # Using managed node groups for easier management
  - name: general-purpose
    instanceType: t3.medium
    desiredCapacity: 3 # Start with 3 nodes for redundancy
    minSize: 1
    maxSize: 5
    volumeSize: 30 # GB
    labels: { role: general }
    # To allow SSH, set ssh: { allow: true } for debugging, but be cautious in production
```

Deploy the cluster:

```bash
eksctl create cluster -f cluster-config.yaml
```

**Install AWS Load Balancer Controller:**

This is crucial for using Ingress with AWS ALB. Follow the official AWS documentation for the most up-to-date installation: [AWS Load Balancer Controller Installation](https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.7/deploy/installation/).

  * **Summary (highly simplified, check docs for full details):**

      * Create IAM Policy and Role for the controller.
      * Attach the IAM Role to the Kubernetes Service Account used by the controller.
      * Install via Helm.


    ```bash
    # Example (check official docs for exact versions/commands)
    # Install cert-manager (prerequisite for some versions)
    helm repo add jetstack https://charts.jetstack.io
    helm repo update
    helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.12.0 --set installCRDs=true

    # Add EKS charts repo
    helm repo add eks https://aws.github.io/eks-charts
    helm repo update

    # Install the controller (ensure you have the right IAM permissions & service account setup)
    helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
        -n kube-system \
        --set clusterName=blog-platform-cluster \
        --set serviceAccount.create=false \
        --set serviceAccount.name=aws-load-balancer-controller \
        --set image.repository=<aws-account-id>.dkr.ecr.<your-aws-region>.amazonaws.com/amazon/aws-load-balancer-controller # Adjust if needed
    ```

#### 1.2. **Create Amazon RDS (PostgreSQL/MySQL)**

Use the AWS Console or AWS CLI.

**Using AWS CLI (example for PostgreSQL):**

```bash
aws rds create-db-instance \
    --db-instance-identifier blog-db \
    --db-instance-class db.t3.micro \
    --engine postgres \
    --engine-version 15.2 \
    --master-username masteruser \
    --master-user-password <your-db-password> \
    --allocated-storage 20 \
    --vpc-security-group-ids sg-xxxxxxxxxxxxxxxxx # Security group allowing EKS nodes to connect
    --db-subnet-group-name <your-db-subnet-group> # Subnet group where DB will reside
    --publicly-accessible false \
    --no-multi-az
```

*Make sure the security group attached to RDS allows inbound connections from your EKS worker nodes (their security groups or CIDR range).*

#### 1.3. **Create Amazon ElastiCache (Redis)**

Use the AWS Console or AWS CLI.

**Using AWS CLI (example for Redis):**

```bash
aws elasticache create-cache-cluster \
    --cache-cluster-id blog-redis \
    --cache-node-type cache.t3.micro \
    --engine redis \
    --engine-version 6.x \
    --num-cache-nodes 1 \
    --security-group-ids sg-xxxxxxxxxxxxxxxxx # Security group allowing EKS nodes to connect
    --cache-subnet-group-name <your-cache-subnet-group>
```

*Again, ensure the security group allows connections from your EKS worker nodes.*

-----

### üê≥ Step 2: Containerize Your Services

Each part of your application needs a `Dockerfile`.

#### 2.1. **Backend (Node.js) `Dockerfile` Example:**

Assume your Node.js API runs on port 3001.

```dockerfile
# backend/Dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 3001

CMD ["npm", "start"]
```

#### 2.2. **Frontend (React) `Dockerfile` Example:**

Assume your React app is built and served by Nginx on port 80.

```dockerfile
# frontend/Dockerfile
FROM node:18-alpine as build-stage
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build # Or yarn build

FROM nginx:stable-alpine as production-stage
COPY --from=build-stage /app/build /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

**Build and Push to ECR:**

You'll do this for both Frontend and Backend, similar to the Basic Level guide. Create separate ECR repositories (e.g., `blog-frontend`, `blog-backend`).

```bash
# For backend
aws ecr create-repository --repository-name blog-backend --region <your-aws-region>
docker build -t blog-backend ./backend
docker tag blog-backend:latest <aws-account-id>.dkr.ecr.<your-aws-region>.amazonaws.com/blog-backend:latest
docker push <aws-account-id>.dkr.ecr.<your-aws-region>.amazonaws.com/blog-backend:latest

# Repeat for frontend: blog-frontend
```

-----

### ‚öôÔ∏è Step 3: Create Helm Charts for Each Service

Helm charts package your Kubernetes deployments. This makes your application configurable and reusable.

#### 3.1. **Helm Chart Structure:**

For each service (e.g., `backend`), create a directory `charts/backend` and run `helm create charts/backend`.

You'll modify `charts/backend/values.yaml` and `charts/backend/templates/deployment.yaml`, `service.yaml`.

#### 3.2. **Backend Helm Chart Example (`charts/backend`):**

  * **`charts/backend/values.yaml`**:

    ```yaml
    # charts/backend/values.yaml
    replicaCount: 2

    image:
      repository: <aws-account-id>.dkr.ecr.<your-aws-region>.amazonaws.com/blog-backend
      pullPolicy: IfNotPresent
      tag: "latest" # This will be overwritten by CI/CD

    service:
      type: ClusterIP # Internal service, exposed via Ingress
      port: 3001 # Port the backend app listens on

    # Database connection details (use Secret/ConfigMap for actual values)
    database:
      host: ""
      name: ""
      user: ""

    redis:
      host: ""
    ```

  * **`charts/backend/templates/deployment.yaml`**:

    ```yaml
    # charts/backend/templates/deployment.yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: {{ include "backend.fullname" . }}
      labels:
        {{- include "backend.labels" . | nindent 4 }}
    spec:
      {{- if not .Values.autoscaling.enabled }}
      replicas: {{ .Values.replicaCount }}
      {{- end }}
      selector:
        matchLabels:
          {{- include "backend.selectorLabels" . | nindent 6 }}
      template:
        metadata:
          {{- with .Values.podAnnotations }}
          annotations:
            {{- toYaml . | nindent 8 }}
          {{- end }}
          labels:
            {{- include "backend.selectorLabels" . | nindent 12 }}
        spec:
          containers:
            - name: {{ .Chart.Name }}
              image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
              imagePullPolicy: {{ .Values.image.pullPolicy }}
              ports:
                - name: http
                  containerPort: {{ .Values.service.port }}
                  protocol: TCP
              env:
                - name: DB_HOST
                  valueFrom:
                    configMapKeyRef:
                      name: backend-config # ConfigMap for non-sensitive data
                      key: DB_HOST
                - name: DB_NAME
                  valueFrom:
                    configMapKeyRef:
                      name: backend-config
                      key: DB_NAME
                - name: DB_USER
                  valueFrom:
                    configMapKeyRef:
                      name: backend-config
                      key: DB_USER
                - name: DB_PASSWORD
                  valueFrom:
                    secretKeyRef: # Secret for sensitive data
                      name: backend-secrets
                      key: DB_PASSWORD
                - name: REDIS_HOST
                  valueFrom:
                    configMapKeyRef:
                      name: backend-config
                      key: REDIS_HOST
              resources:
                {{- toYaml .Values.resources | nindent 12 }}
    ```

  * **`charts/backend/templates/service.yaml`**:

    ```yaml
    # charts/backend/templates/service.yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: {{ include "backend.fullname" . }}
      labels:
        {{- include "backend.labels" . | nindent 4 }}
    spec:
      type: {{ .Values.service.type }}
      ports:
        - port: {{ .Values.service.port }}
          targetPort: http
          protocol: TCP
          name: http
      selector:
        {{- include "backend.selectorLabels" . | nindent 8 }}
    ```

**Repeat for Frontend (`charts/frontend`):**

The Frontend chart will be similar, but its `service.yaml` might also be `ClusterIP` as it will be exposed via Ingress. Ensure the `containerPort` matches what your Nginx serves (e.g., 80).

-----

### üîë Step 4: Manage Configurations and Secrets

Never hardcode sensitive information.

#### 4.1. **ConfigMap for Non-Sensitive Data:**

Create a `ConfigMap` for your backend. This will hold your RDS endpoint and Redis endpoint.

```yaml
# kubernetes/backend-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: backend-config
data:
  DB_HOST: <your-rds-endpoint> # e.g., blog-db.xxxx.us-east-1.rds.amazonaws.com
  DB_NAME: your_database_name
  DB_USER: masteruser
  REDIS_HOST: <your-elasticache-redis-endpoint> # e.g., blog-redis.xxxx.usw2.cache.amazonaws.com
```

Apply this to your cluster: `kubectl apply -f kubernetes/backend-configmap.yaml`

#### 4.2. **Secrets for Sensitive Data (AWS Secrets Manager):**

For passwords, use AWS Secrets Manager. You'll create a secret in AWS and then retrieve it in your Kubernetes manifests using either:

1.  **Directly reference with `external-secrets` operator (Recommended for production):** This requires installing the `external-secrets` operator in your cluster. It watches for `ExternalSecret` resources and syncs them into native Kubernetes `Secret`s.
2.  **Manually create Kubernetes Secret:** Less ideal for CI/CD, but simpler initially.

**Example for Manual Kubernetes Secret (for initial setup):**

```bash
# Create a secret in AWS Secrets Manager for your DB password
aws secretsmanager create-secret --name blog-db-password --secret-string '{"DB_PASSWORD":"<your-db-password>"}'

# Then, retrieve and create a Kubernetes Secret (manually or via CI/CD script)
# NOTE: This is base64 encoded. In a real CI/CD, you'd fetch this securely.
kubectl create secret generic backend-secrets --from-literal=DB_PASSWORD='<your-base64-encoded-db-password>'
```

**Recommended: Using `external-secrets` (High-level overview):**

  * Install the `external-secrets` operator to your cluster.

  * Create a `SecretStore` to tell `external-secrets` how to access AWS Secrets Manager.

  * Create an `ExternalSecret` resource that references your AWS Secret and defines how it maps to a Kubernetes Secret.

    ```yaml
    # kubernetes/external-secret.yaml
    apiVersion: external-secrets.io/v1beta1
    kind: ExternalSecret
    metadata:
      name: backend-secrets
    spec:
      secretStoreRef:
        name: aws-secret-store # Name of your SecretStore
        kind: SecretStore
      target:
        name: backend-secrets # Name of the Kubernetes Secret to create
        creationPolicy: Owner
      data:
        - secretKey: DB_PASSWORD # Key in the K8s secret
          remoteRef:
            key: blog-db-password # Name of the secret in AWS Secrets Manager
            property: DB_PASSWORD # Key within the AWS secret (if it's a JSON string)
    ```

-----

### üîÑ Step 5: Set up CI/CD with GitHub Actions

This is where automation shines. You'll create `.github/workflows` files in your Frontend and Backend repositories.

#### 5.1. **IAM Role for GitHub Actions:**

Create an IAM Role that GitHub Actions can assume to interact with AWS (ECR, EKS). This involves OIDC federation.

  * Follow AWS documentation: [Configuring OpenID Connect (OIDC) in your AWS account](https://www.google.com/search?q=https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc_github.html).
  * Grant this role permissions to:
      * `ecr:GetDownloadUrlForLayer`, `ecr:BatchGetImage`, `ecr:BatchCheckLayerAvailability`, `ecr:PutImage`, `ecr:InitiateLayerUpload`, `ecr:UploadLayerPart`, `ecr:CompleteLayerUpload` (for ECR push/pull)
      * `eks:DescribeCluster` (to get EKS cluster info)
      * `sts:AssumeRoleWithWebIdentity` (for OIDC)
      * `sts:GetCallerIdentity`
      * `kubectl` access via IRSA for `kube-system` namespace.

#### 5.2. **Backend CI/CD Workflow (`.github/workflows/backend-ci-cd.yaml`):**

```yaml
# .github/workflows/backend-ci-cd.yaml
name: Backend CI/CD

on:
  push:
    branches:
      - main
    paths:
      - 'backend/**' # Trigger only if changes are in the backend directory

env:
  AWS_REGION: <your-aws-region>
  ECR_REPOSITORY: blog-backend
  EKS_CLUSTER_NAME: blog-platform-cluster
  # Ensure your Helm chart is at charts/backend relative to root
  HELM_CHART_PATH: charts/backend

permissions:
  id-token: write # This is required for OIDC
  contents: read

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::<aws-account-id>:role/GitHubActionsRole # Your GitHub Actions IAM role ARN
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and tag the Docker image
        id: build-image
        run: |
          docker build -t $ECR_REPOSITORY ./backend
          docker tag $ECR_REPOSITORY:latest ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:${{ github.sha }}
          docker tag $ECR_REPOSITORY:latest ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:latest

      - name: Push Docker image to ECR
        run: |
          docker push ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:${{ github.sha }}
          docker push ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:latest

      - name: Set up kubectl
        uses: aws-actions/setup-kubectl@v3
        with:
          version: 'latest' # Or a specific version, e.g., '1.28.0'

      - name: Set up Helm
        uses: azure/setup-helm@v1
        with:
          version: 'v3.12.0' # Or your preferred Helm version

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}

      - name: Deploy with Helm
        run: |
          helm upgrade --install blog-backend ${{ env.HELM_CHART_PATH }} \
            --namespace default \
            --set image.tag=${{ github.sha }} \
            --atomic --timeout 5m0s # Ensures a complete rollback on failure
```

**Repeat for Frontend CI/CD Workflow (`.github/workflows/frontend-ci-cd.yaml`):**

Similar workflow, but adjust `ECR_REPOSITORY` to `blog-frontend`, `HELM_CHART_PATH` to `charts/frontend`, and `paths` to `frontend/**`.

-----

### üåê Step 6: Configure Ingress for Public Access

The Ingress Controller (AWS ALB Ingress Controller) will create an Application Load Balancer (ALB) and route traffic to your services.

#### 6.1. **Create Ingress Resource:**

```yaml
# kubernetes/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: blog-platform-ingress
  annotations:
    kubernetes.io/ingress.class: alb # Specify the ALB Ingress Controller
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip # Target pods directly
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS": 443}]' # Listen on HTTP and HTTPS
    alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig": { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:<your-aws-region>:<aws-account-id>:certificate/<your-certificate-id> # ACM ARN for HTTPS
    alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=600 # Optional: configure ALB
    # Add CORS if needed: alb.ingress.kubernetes.io/cors-config: '{"AllowOrigins": "*", "AllowMethods": "GET,PUT,POST,DELETE,OPTIONS", "AllowHeaders": "*", "MaxAge": "86400"}'
spec:
  rules:
    - host: <your-domain.com> # Optional, if you have a custom domain
      http:
        paths:
          - path: /api/* # Routes /api/ to backend
            pathType: Prefix
            backend:
              service:
                name: blog-backend # Name of your backend K8s service
                port:
                  number: 3001 # Port of your backend K8s service
          - path: /* # Routes all other paths to frontend
            pathType: Prefix
            backend:
              service:
                name: blog-frontend # Name of your frontend K8s service
                port:
                  number: 80 # Port of your frontend K8s service
          - path: /
            pathType: Exact
            backend:
              service:
                name: blog-frontend
                port:
                  number: 80
```

*Replace placeholders like `<your-domain.com>`, `<your-aws-region>`, `<aws-account-id>`, and `<your-certificate-id>` (from AWS Certificate Manager).*

Apply this Ingress: `kubectl apply -f kubernetes/ingress.yaml`

Wait a few minutes for the ALB to provision. You can get its DNS name by checking:

```bash
kubectl get ingress blog-platform-ingress
```

Look for the `ADDRESS` field, which will be the public URL of your application.

-----

### üëÄ Step 7: Basic Monitoring with CloudWatch

AWS EKS integrates with CloudWatch for basic monitoring.

  * **Pod Logs**: By default, container logs are sent to CloudWatch Logs if you enable Container Insights or configure Fluentd/Fluent Bit.
  * **Metrics**: EKS automatically sends control plane metrics to CloudWatch. For node and pod metrics, you'd typically deploy Container Insights.

**Enabling Container Insights for EKS:**

```bash
aws cloudwatch put-dashboard --dashboard-name YourEksDashboard --dashboard-body file://your-dashboard-json-file.json # Optional, custom dashboards
eksctl utils enable-secrets-encryption --cluster=blog-platform-cluster # Good practice for EKS
# Deploy CloudWatch Agent for Container Insights
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/cloudwatch-agent-rbac.yaml
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/cloudwatch-agent.yaml
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/fluentd.yaml # For logs
```

*Always refer to the official AWS documentation for the latest commands and best practices for Container Insights.*

-----

## üéì Skills Learned:

By successfully completing this project, you will have gained valuable skills in:

  * **Real-world Kubernetes CI/CD**: You've built an automated pipeline that takes your code from commit to deployment on a Kubernetes cluster.
  * **Helm for Configuration Reuse**: You've used Helm to manage and templatize your Kubernetes deployments, making them reusable and version-controlled.
  * **Ingress Controller for Routing and HTTPS**: You've configured an Ingress Controller to expose multiple services under a single public endpoint, handle URL routing, and enable HTTPS using ACM certificates.
  * **Managed Services Integration**: You've integrated AWS RDS and ElastiCache with your Kubernetes application.
  * **Secure Configuration Management**: You've used ConfigMaps and understood the importance of Secrets for sensitive data.

-----

## Clean Up (Crucial\!)

**Remember to tear down all resources to avoid ongoing costs.**

1.  **Delete Kubernetes resources:**
    ```bash
    kubectl delete -f kubernetes/ingress.yaml
    helm uninstall blog-backend --namespace default
    helm uninstall blog-frontend --namespace default
    kubectl delete configmap backend-config
    kubectl delete secret backend-secrets # Or ExternalSecret if used
    ```
2.  **Delete the EKS cluster:**
    ```bash
    eksctl delete cluster --name blog-platform-cluster --region <your-aws-region>
    ```
3.  **Delete ECR repositories:**
    ```bash
    aws ecr delete-repository --repository-name blog-backend --force --region <your-aws-region>
    aws ecr delete-repository --repository-name blog-frontend --force --region <your-aws-region>
    ```
4.  **Delete RDS Instance:** (Via AWS Console or CLI)
    ```bash
    aws rds delete-db-instance --db-instance-identifier blog-db --skip-final-snapshot
    ```
5.  **Delete ElastiCache Redis Cluster:** (Via AWS Console or CLI)
    ```bash
    aws elasticache delete-cache-cluster --cache-cluster-id blog-redis
    ```
6.  **Delete AWS Secrets Manager secrets** (if created manually).
7.  **Delete the IAM Role for GitHub Actions.**

-----

This guide provides a solid foundation for deploying complex applications on EKS with CI/CD. As you progress, you can explore more advanced topics like horizontal pod autoscaling, service meshes, and more sophisticated monitoring. Good luck with your project\!